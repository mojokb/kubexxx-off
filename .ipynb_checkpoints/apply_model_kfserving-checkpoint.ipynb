{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 201011 14:25:14 append:50] Building image using Append builder...\n",
      "[I 201011 14:25:14 base:105] Creating docker context: /tmp/fairing_context_4am3xv9i\n",
      "[I 201011 14:25:15 converted_notebook:127] Converting apply_model_kfserving.ipynb to apply_model_kfserving.py\n",
      "[I 201011 14:25:15 docker_creds_:234] Loading Docker credentials for repository 'brightfly/kubeflow-jupyter-lab:tf2.0-cpu'\n",
      "[W 201011 14:25:17 append:54] Image successfully built in 2.718331407988444s.\n",
      "[W 201011 14:25:17 append:94] Pushing image kubeflow-registry.default.svc.cluster.local:30000/apply-model-kfserving:CEF7B942...\n",
      "[I 201011 14:25:17 docker_creds_:234] Loading Docker credentials for repository 'kubeflow-registry.default.svc.cluster.local:30000/apply-model-kfserving:CEF7B942'\n",
      "[W 201011 14:25:17 append:81] Uploading kubeflow-registry.default.svc.cluster.local:30000/apply-model-kfserving:CEF7B942\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:d846ead9aa38bc0d35dd500ada5349fe42efb96c89db08b8abcb9ad949332c2a exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:7fc152dfb3a6b5c9a436b49ff6cd72ed7eb5f1fd349128b50ee04c3c5c2355fb exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:c2f81144f815902f9c6e6f7883068544e35924f0efe2275bc41c3d0c558f394c exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:ee671aafb583e2321880e275c94d49a49185006730e871435cd851f42d2a775d exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:fd781ca227d0199735cceb67afa81e2a073b5ef5867ca6e96ad46e002a03252a exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:af228bb15b867acbee0d6df28dbb42a8218948fdde64833bd021a255a99a2690 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:7acbfba21e38804c20c4da292d2f99d88d317b83440fb2f3de0a620edf2b9595 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:d0d480fe0d0ab233a90471379d9d3789d4153ad4611d101cfefdfc0c507d9356 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:df80607e3e38dc3f117e967a36620c42f791afc9ca0568900d13d84c1e3a38bb exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:d83811f270d56d34a208f721f3dbf1b9242d1900ad8981fc7071339681998a31 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:485ea80d093de507a5ccd36effaf8dad03b67a1063edbd427fedfe667c9155bc exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:8e7d3ffcd500d3ed0b2ee2449a36a44601b8e282cc6d541ab93f1189d4a2cf93 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:5667fdb72017d1fb364744ca1abf7b6f3bbe9c98c3786f294a461c2866db69ab exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:069de100aaecb1299b09dab29a4eb39a2ca6a5f8c0a033b65ff0e15e9ea39a24 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:6ac505cbabeccba798e608e1bb80ae66f497c2c856733800e1db060e3c875917 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:50f1fe304a9431ea025aa6ee5e8e45826fa62640a83e55be8bd3c227119cbcd2 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:872efc07c3d848e0f55b7cbce9866a8dea7b76d8c1f131801934ea0d856b15c5 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:fb9676c4102241f220b864e98c53676e27c407c6ecfbb13c2cbc1fa4de8f1811 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:1c60aaf19cc4c142934f390281975f61956475c205b5895711f839a91f927779 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:66257906239d377cd700c566b27f12895ccefcd8d95eae7377f600208151d8e0 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:280] Layer sha256:8f64ecfab6c102a62dd5d912d96113603663ad8b436701bf2dbd1aa9630882e7 exists, skipping\n",
      "[I 201011 14:25:17 docker_session_:284] Layer sha256:70e63c30e6be53abaccf629e2da8883709b90a4e67e20b16ce06c3c480051ee6 pushed.\n",
      "[I 201011 14:25:17 docker_session_:284] Layer sha256:f9bcaf61e30e7bd97e6497c0cfb88b6ff6cfc6869c1fbe39b3142a295e1cd1e0 pushed.\n",
      "[I 201011 14:25:17 docker_session_:334] Finished upload of: kubeflow-registry.default.svc.cluster.local:30000/apply-model-kfserving:CEF7B942\n",
      "[W 201011 14:25:17 append:99] Pushed image kubeflow-registry.default.svc.cluster.local:30000/apply-model-kfserving:CEF7B942 in 0.2413626939523965s.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import logging\n",
    "import argparse\n",
    "from minio import Minio\n",
    "from minio.error import ResponseError\n",
    "from kubernetes import client\n",
    "from kfserving import KFServingClient\n",
    "from kfserving import constants\n",
    "from kfserving import utils\n",
    "from kfserving import V1alpha2EndpointSpec\n",
    "from kfserving import V1alpha2PredictorSpec\n",
    "from kfserving import V1alpha2TensorflowSpec\n",
    "from kfserving import V1alpha2InferenceServiceSpec\n",
    "from kfserving import V1alpha2InferenceService\n",
    "from kubernetes.client import V1ResourceRequirements\n",
    "\n",
    "class ApplyModelKfserving(object):\n",
    "    def copy_model_version(self, namespace, version):\n",
    "\n",
    "        # by using default minio\n",
    "        mc = Minio(\"minio-service.kubeflow.svc.cluster.local:9000\",\n",
    "                    access_key=\"minio\",\n",
    "                    secret_key=\"minio123\",\n",
    "                    secure=False)  \n",
    "        model_bucket_name = f'{namespace}-model-result'\n",
    "        print(\"model_bucket_name \" + model_bucket_name) \n",
    "        bucket_exists = mc.bucket_exists(model_bucket_name)\n",
    "        if bucket_exists:\n",
    "            lists = mc.list_objects(model_bucket_name, \n",
    "                                    prefix=f\"result/saved_model/{version}\", \n",
    "                                    recursive=True)\n",
    "            copy_model_dir = \"/model/result/saved_model\"\n",
    "            pathlib.Path(copy_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "            for object in lists:\n",
    "                if os.path.isdir(copy_model_dir):\n",
    "                    mc.fget_object(model_bucket_name, object.object_name, \"/model/\" + object.object_name)    \n",
    "                    \n",
    "            for (path, dir, files) in os.walk(copy_model_dir):\n",
    "                for filename in files:\n",
    "                    print(\"%s/%s\" % (path, filename))\n",
    "        else:\n",
    "            raise Exception(\"bucket not exists\")\n",
    "            \n",
    "    \n",
    "    \n",
    "    def apply_kfserving(self, model_name, namespace, pvc_name):\n",
    "        api_version = constants.KFSERVING_GROUP + '/' + constants.KFSERVING_VERSION\n",
    "        storage_uri = f'pvc://{pvc_name}/result/saved_model'\n",
    "        print(\"Stroage_uri \" + storage_uri)\n",
    "        default_endpoint_spec = V1alpha2EndpointSpec(\n",
    "                                  predictor=V1alpha2PredictorSpec(\n",
    "                                    tensorflow=V1alpha2TensorflowSpec(\n",
    "                                      storage_uri=storage_uri,\n",
    "                                      resources=V1ResourceRequirements(\n",
    "                                          requests={'cpu':'100m','memory':'1Gi'},\n",
    "                                          limits={'cpu':'100m', 'memory':'1Gi'}))))\n",
    "\n",
    "        isvc = V1alpha2InferenceService(api_version=api_version,\n",
    "                                  kind=constants.KFSERVING_KIND,\n",
    "                                  metadata=client.V1ObjectMeta(\n",
    "                                      name=model_name, namespace=\"kubeflow\"),\n",
    "                                  spec=V1alpha2InferenceServiceSpec(default=default_endpoint_spec))        \n",
    "        KFServing = KFServingClient()\n",
    "        # if model server is exist\n",
    "        if KFServing.get(model_name, namespace=\"kubeflow\"):\n",
    "            KFServing.patch(model_name, isvc)\n",
    "            print(\"Patched KFServing service\")\n",
    "        else:\n",
    "            KFServing.create(isvc)\n",
    "            print(\"Created KFServing service\")\n",
    "            \n",
    "        KFServing.get(model_name, namespace=\"kubeflow\", watch=True, timeout_seconds=360) \n",
    "        \n",
    "    def apply(self):\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--model_name', required=False, type=str, default=\"mnist_kfserving\")\n",
    "        parser.add_argument('--namespace', required=False, type=str, default=\"amaramusic\")        \n",
    "        parser.add_argument('--pvc_name', required=False, type=str, default=\"model_pvc\")        \n",
    "        parser.add_argument('--version', required=False, type=str, default=\"001\")\n",
    "        args = parser.parse_args()     \n",
    "        \n",
    "        print(f\"{args.pvc_name}\")\n",
    "        \n",
    "        self.copy_model_version(args.namespace, args.version)\n",
    "        self.apply_kfserving(args.model_name, args.namespace, args.pvc_name)\n",
    "        \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "        \"\"\"\n",
    "        from kubeflow import fairing\n",
    "        from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "\n",
    "        DOCKER_REGISTRY = 'kubeflow-registry.default.svc.cluster.local:30000'\n",
    "        fairing.config.set_builder(\n",
    "            'append',\n",
    "            image_name='mnist-katib-job',\n",
    "            base_image='brightfly/katib-sdk:0.0.1',\n",
    "            registry=DOCKER_REGISTRY,\n",
    "            push=True)\n",
    "        # cpu 1, memory 1GiB\n",
    "        fairing.config.set_deployer('job',\n",
    "                                    namespace='amaramusic'\n",
    "                                    )\n",
    "        fairing.config.run()        \n",
    "        \"\"\"\n",
    "        from kubeflow.fairing.builders.append.append import AppendBuilder\n",
    "        from kubeflow.fairing.preprocessors.converted_notebook import ConvertNotebookPreprocessor\n",
    "\n",
    "        DOCKER_REGISTRY = 'kubeflow-registry.default.svc.cluster.local:30000'\n",
    "        base_image='brightfly/kubeflow-jupyter-lab:tf2.0-cpu'\n",
    "        image_name='apply-model-kfserving'\n",
    "\n",
    "        builder = AppendBuilder(\n",
    "            registry=DOCKER_REGISTRY,\n",
    "            image_name=image_name,\n",
    "            base_image=base_image,\n",
    "            push=True,\n",
    "            \n",
    "            preprocessor=ConvertNotebookPreprocessor(\n",
    "                notebook_file=\"apply_model_kfserving.ipynb\" )\n",
    "            )\n",
    "        builder.build()         \n",
    "    else:\n",
    "        serving = ApplyModelKfserving()\n",
    "        serving.apply()        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
